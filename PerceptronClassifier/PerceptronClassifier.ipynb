{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning\n",
    "## Implementing Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the PerceptronClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001,epoch=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self._b = 0.0  \n",
    "        self._w = None  # weights assigned to input features\n",
    "        self.misclassified_samples = []# count of errors during each iteration\n",
    "        self.epoch = epoch\n",
    "\n",
    "    \n",
    "    def fit(self, x: np.array, y: np.array):\n",
    "        #self._w = np.zeros(x.shape[1])\n",
    "        self._w = np.random.randn(x.shape[1])*0.01\n",
    "        self._b = 0.0\n",
    "\n",
    "        for _ in range(self.epoch):\n",
    "            errors = 0\n",
    "            for xi, yi in zip(x, y):\n",
    "                # for each sample compute the update value\n",
    "                update = self.learning_rate * (yi - self.predict(xi))\n",
    "                # and apply it to the y-intercept and weights array\n",
    "                self._b += update\n",
    "                self._w += update * xi\n",
    "                errors += int(update != 0.0)\n",
    "            self.misclassified_samples.append(errors)\n",
    "        return self\n",
    "    \n",
    "    #Let the input pass through the activation function\n",
    "    def f(self, x: np.array) -> float:\n",
    "        a = np.dot(x, self._w) + self._b\n",
    "        return self.sigmoid(a)\n",
    "\n",
    "    #Predict the label\n",
    "    def predict(self, x: np.array): \n",
    "        return np.where(self.f(x) > 0.5, 1, 0)\n",
    "\n",
    "    def predict_prob(self, x: np.array):\n",
    "        self.x = x \n",
    "        res_list = []\n",
    "        for sample in x:\n",
    "            res_list.append(self.f(sample))  \n",
    "        return np.array(res_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Diabethic Retinopathy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151, 19)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('messidor_features.csv', index_col = 0)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the perfomrance of the perceptron classifier on the daibetic retinopathy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((575, 18), (576, 18))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.reset_index(drop=False)\n",
    "X = dataset.iloc[:,:18].values\n",
    "Y = dataset[\"Class\"].values\n",
    "X = X.astype(float)\n",
    "Y = np.array([1 if i == \"b'1'\" else 0 for i in Y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.5,\n",
    "                                                    random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.05907962, -3.01458443, -0.98319715, ..., -0.21488684,\n",
       "          0.95897316,  1.34298837],\n",
       "        [ 0.05907962,  0.33172068,  0.71799885, ..., -0.21488684,\n",
       "          1.11741976,  0.10788345],\n",
       "        [ 0.05907962,  0.33172068,  0.83398949, ..., -0.21488684,\n",
       "          0.02649378,  1.28827565],\n",
       "        ...,\n",
       "        [ 0.05907962,  0.33172068,  0.02205503, ..., -0.21488684,\n",
       "          0.21399555,  0.63547042],\n",
       "        [ 0.05907962,  0.33172068, -0.55789815, ..., -0.21488684,\n",
       "         -1.29817621, -0.68818131],\n",
       "        [ 0.05907962,  0.33172068, -1.29250551, ..., -0.21488684,\n",
       "         -0.75636773,  0.03175675]]),\n",
       " (576, 18))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My accuracy is 0.65\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train, y_train)\n",
    "results= p.predict(X_test)\n",
    "accuracy = accuracy_score(p.predict(X_test),y_test)\n",
    "print(\"My accuracy is %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0\n",
      " 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
      " 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1\n",
      " 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1\n",
      " 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0\n",
      " 1 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0\n",
      " 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1\n",
      " 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1\n",
      " 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 & 4: Add Different Activations & Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reimplement the PerceptronClassifier class adding an activation function option and L2 regularisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronClassifier2(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def regular_method(self): \n",
    "        if self.regularization == 'L2':\n",
    "            self.reg_strength=1000\n",
    "        elif self.regularization == 'Normal':\n",
    "            self.reg_strength=0\n",
    "        return self.reg_strength\n",
    "        \n",
    "    def __init__(self,activation_function = 'tanh',regularization='Normal',learning_rate = 0.00001, epochs = 10):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.reg_strength = 10000\n",
    "        self._b = 0.0\n",
    "        self.activation_function = activation_function\n",
    "        self.regularization = regularization\n",
    "    \n",
    "\n",
    "    #Calculate the cost\n",
    "    def cost_computation(self, W, X, Y):\n",
    "        \n",
    "        # Hinge loss calculation\n",
    "        n = X.shape[0]\n",
    "        distances = 1 - Y * (np.dot(X, W))\n",
    "        distances[distances < 0] = 0 # make all distances less than 0 equal to 0.\n",
    "        hinge_loss = self.regular_method()*(np.nansum(distances)/n)\n",
    "\n",
    "        # Calculate cost\n",
    "        cost = 1/2 * np.dot(W,W) + hinge_loss\n",
    "        return cost\n",
    "    \n",
    "    #Update the gradient\n",
    "    def cost_gradient_computation(self, W, X_ij, Y_ij):\n",
    "        \n",
    "        if type(Y_ij) == np.float64:\n",
    "            Y_ij = np.array([Y_ij])\n",
    "            X_ij = np.array([X_ij])  # gives multidimensional array\n",
    "            \n",
    "        distance = 1 - (Y_ij * np.dot(X_ij, W))\n",
    "        dw = np.zeros(len(W))\n",
    "        \n",
    "        if max(0,distance) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (self.reg_strength * Y_ij* X_ij)\n",
    "        dw += di\n",
    "        return dw\n",
    "    \n",
    "    #train the model\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        # Stochastic gradient descent\n",
    "        max_epochs = 100\n",
    "        #self.weights = np.zeros(X.shape[1])\n",
    "        self.weights = np.random.randn(X.shape[1])*0.01\n",
    "        nth = 0\n",
    "        #prev_cost = 9999999\n",
    "        cost_threshold = 0.001  # in percent\n",
    "        \n",
    "        # stochastic gradient descent\n",
    "        for epoch in range(1,max_epochs):\n",
    "            \n",
    "            # shuffle\n",
    "            X_i, Y_i = X, Y\n",
    "            \n",
    "            for i, x in enumerate(X_i):\n",
    "\n",
    "                ascent = self.cost_gradient_computation(self.weights, x, Y_i[i])\n",
    "                self.weights = self.weights - (self.learning_rate * ascent)\n",
    "            \n",
    "            if epoch == 2 ** nth:\n",
    "                cost = self.cost_computation(self.weights, X, Y)\n",
    "                print(\"Epoch is: {} and Cost is: {} \\n {}\".format(epoch, cost, self.weights))\n",
    "                nth += 1\n",
    "                \n",
    "        return self.weights\n",
    "    \n",
    "    #Outputs the predictions for all samples\n",
    "    def predict_prob(self, X, Y):\n",
    "        \n",
    "        Y_te_predictions = np.array([])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            X_ = np.dot(X, self.weights) + self._b   \n",
    "            Yp = np.where(self.forward_activation(X_) > 0.5, 1, 0)\n",
    "            Y_te_predictions = np.append(Y_te_predictions, Yp)\n",
    "            \n",
    "        return Y_te_predictions\n",
    "\n",
    "    def forward_activation(self, X): \n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            return 1.0/(1.0 + np.exp(-X))\n",
    "        elif self.activation_function == \"tanh\":\n",
    "            return np.tanh(X)\n",
    "\n",
    "    # predict the label of the sample\n",
    "    def predict(self, X):\n",
    "        a = np.dot(X, self.weights) + self._b        \n",
    "        return np.where(self.forward_activation(a) > 0.5, 1, 0)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151, 19)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('messidor_features.csv', index_col = 0)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((575, 18), (576, 18))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.reset_index(drop=False)\n",
    "X = dataset.iloc[:,:18].values\n",
    "Y = dataset[\"Class\"].values\n",
    "X = X.astype(float)\n",
    "Y = np.array([1 if i == \"b'1'\" else 0 for i in Y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.5,\n",
    "                                                    random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1 and Cost is: 2.30147525281711 \n",
      " [ 1.29038907 -0.7369357   0.75444061  0.43235859  0.05599408 -0.4072961\n",
      " -0.67213458 -0.49929725  0.32546373 -0.18641708 -0.51165204 -0.35430248\n",
      "  0.34766497  0.19133626  0.22429538  0.00664155 -0.08909395 -0.15748932]\n",
      "Epoch is: 2 and Cost is: 2.275159759935572 \n",
      " [ 1.28299058 -0.73271046  0.750115    0.42987965  0.05567304 -0.40496086\n",
      " -0.66828088 -0.49643451  0.32359767 -0.18534825 -0.50871847 -0.35227107\n",
      "  0.34567162  0.19023923  0.22300937  0.00660347 -0.08858312 -0.15658635]\n",
      "Epoch is: 4 and Cost is: 2.223428022279714 \n",
      " [ 1.26832063 -0.72433251  0.74153805  0.42496433  0.05503646 -0.40033046\n",
      " -0.66063963 -0.49075819  0.3198976  -0.18322894 -0.50290169 -0.34824314\n",
      "  0.34171915  0.188064    0.22045944  0.00652797 -0.08757025 -0.15479591]\n",
      "Epoch is: 8 and Cost is: 2.1234665727872124 \n",
      " [ 1.23948203 -0.70786291  0.72467723  0.41530165  0.05378506 -0.39122789\n",
      " -0.64561825 -0.47959951  0.31262388 -0.17906275 -0.4914669  -0.34032492\n",
      "  0.33394926  0.18378787  0.21544672  0.00637954 -0.08557911 -0.15127622]\n",
      "Epoch is: 16 and Cost is: 1.9368239049809457 \n",
      " [ 1.18375708 -0.67603862  0.69209701  0.39663041  0.05136698 -0.37363897\n",
      " -0.61659238 -0.45803755  0.29856886 -0.1710124  -0.4693714  -0.3250245\n",
      "  0.31893549  0.17552509  0.20576061  0.00609273 -0.08173162 -0.1444751 ]\n",
      "Epoch is: 32 and Cost is: 1.6113116698437255 \n",
      " [ 1.07971043 -0.61661803  0.63126495  0.36176847  0.04685207 -0.34079787\n",
      " -0.56239683 -0.41777822  0.27232607 -0.15598122 -0.42811588 -0.29645639\n",
      "  0.29090257  0.16009726  0.18767522  0.0055572  -0.0745478  -0.13177642]\n",
      "Epoch is: 64 and Cost is: 1.115214439744261 \n",
      " [ 0.89824894 -0.51298614  0.52517143  0.30096787  0.03897788 -0.28352169\n",
      " -0.46787763 -0.34756434  0.2265576  -0.12976624 -0.3561646  -0.24663245\n",
      "  0.24201204  0.13319052  0.15613359  0.00462323 -0.06201893 -0.10962942]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.73450458, -0.41947244,  0.42943644,  0.24610358,  0.03187249,\n",
       "       -0.23183772, -0.38258688, -0.28420585,  0.18525777, -0.10611078,\n",
       "       -0.29123834, -0.20167312,  0.19789498,  0.10891084,  0.12767156,\n",
       "        0.00378045, -0.05071332, -0.08964476])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = PerceptronClassifier2()\n",
    "p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "My accuracy is 0.54\n"
     ]
    }
   ],
   "source": [
    "results= p.predict_prob(X_test,y_test)\n",
    "print(results)\n",
    "\n",
    "results_1= p.predict(X_test)\n",
    "accuracy = accuracy_score(p.predict(X_test),y_test)\n",
    "print(\"My accuracy is %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hyper-parameter tuning and evaluate models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_param_grid = {\n",
    "              'activation_function':['sigmoid', 'tanh'],\n",
    "    'regularization':['L2','Normal']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch is: 1 and Cost is: 951.41884582053 \n",
      " [ 1.29733482 -0.40729615  0.87735285  0.51920851  0.10138385 -0.42421537\n",
      " -0.71754973 -0.64146856  0.45355845 -0.04832531 -0.22316186 -0.32810782\n",
      "  0.27143999  0.06273603  0.12998151 -0.31030527 -0.13149339 -0.05875337]\n",
      "Epoch is: 2 and Cost is: 872.1082621685349 \n",
      " [ 1.43185215 -0.27555028  0.97828034  0.61039524  0.2083728  -0.30529879\n",
      " -0.56023207 -0.42341304  0.41696417 -0.02833649 -0.24238353 -0.3994931\n",
      "  0.22129963  0.04281268  0.19340874 -0.15863085 -0.05454392 -0.21483281]\n",
      "Epoch is: 4 and Cost is: 860.7279561741279 \n",
      " [ 1.69916888 -0.24383172  0.95193162  0.57389968  0.1858695  -0.32551537\n",
      " -0.52638958 -0.28706513  0.44033723 -0.0455844  -0.29762877 -0.50749705\n",
      "  0.20413385  0.0315277   0.25896843 -0.0794428  -0.04600357 -0.26500061]\n",
      "Epoch is: 8 and Cost is: 846.9639118860716 \n",
      " [ 2.2199893  -0.2406379   0.91803473  0.50365847  0.12015738 -0.39476985\n",
      " -0.50933692 -0.13962645  0.47067385 -0.01778962 -0.32166881 -0.65650218\n",
      "  0.20559378  0.02792149  0.34318486 -0.07229698 -0.0787285  -0.28175665]\n",
      "Epoch is: 16 and Cost is: 821.2318405783029 \n",
      " [ 3.22639642 -0.20107191  0.97465392  0.44487958  0.07397082 -0.4649906\n",
      " -0.48718281  0.07351861  0.456258    0.03873061 -0.31021965 -0.80866628\n",
      "  0.33233599  0.09553418  0.36680129 -0.11327987 -0.02969848 -0.21133847]\n",
      "Epoch is: 32 and Cost is: 787.7397024384263 \n",
      " [ 5.09919998 -0.19328353  1.05564532  0.34291755  0.02394111 -0.56169491\n",
      " -0.52192081  0.3041569   0.40739064  0.09358344 -0.25217425 -0.96142132\n",
      "  0.74035114  0.29297393  0.16854968 -0.17113666 -0.03116881 -0.17765138]\n",
      "Epoch is: 64 and Cost is: 725.9740965230656 \n",
      " [ 8.29378057 -0.11655665  1.17056373  0.13277555 -0.07019292 -0.67846693\n",
      " -0.57978454  0.36400556  0.25203831  0.04173792  0.04095832 -1.17753427\n",
      "  0.86099028  0.2238137   0.10128386  0.02581256 -0.03374388 -0.14727263]\n"
     ]
    }
   ],
   "source": [
    "p_pipe = GridSearchCV(PerceptronClassifier2(),per_param_grid,\n",
    "                      verbose = 1, n_jobs = -1)\n",
    "p_pipe = p_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_function': 'tanh', 'regularization': 'L2'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1 and Cost is: 1044.1048211787615 \n",
      " [ 1.27394475 -0.56672162  0.78679301  0.43873598  0.06737033 -0.40577358\n",
      " -0.82881976 -0.81609332  0.32213678 -0.08618461 -0.23813283 -0.2307765\n",
      "  0.43033992  0.27373938  0.34756495  0.01120852 -0.07143653 -0.6625867 ]\n",
      "Epoch is: 2 and Cost is: 880.2956916738569 \n",
      " [ 1.40035941 -0.28022281  0.97344645  0.62189682  0.25711441 -0.20370279\n",
      " -0.60712693 -0.53366715  0.3862379  -0.05496908 -0.24876016 -0.3744859\n",
      "  0.28056184  0.13261516  0.224545   -0.09207094 -0.10289568 -0.4265029 ]\n",
      "Epoch is: 4 and Cost is: 861.9583428812629 \n",
      " [ 1.66159342 -0.21814493  0.94215688  0.58211692  0.2336669  -0.2160092\n",
      " -0.54774688 -0.3488879   0.44636766 -0.05742132 -0.30250456 -0.48271523\n",
      "  0.25760095  0.11501235  0.1912129  -0.09308863 -0.06286418 -0.31357759]\n",
      "Epoch is: 8 and Cost is: 848.3999206034437 \n",
      " [ 2.18329011 -0.21527497  0.8934832   0.49728593  0.15887149 -0.29134518\n",
      " -0.53552699 -0.17799408  0.48985352 -0.00708191 -0.32051045 -0.66690611\n",
      "  0.21140737  0.07129338  0.23377829 -0.04410781 -0.07351996 -0.28710303]\n",
      "Epoch is: 16 and Cost is: 822.3008601517561 \n",
      " [ 3.19134539 -0.17643955  0.94370919  0.44108666  0.1013989  -0.38202224\n",
      " -0.51433144  0.03421361  0.45735319  0.04322789 -0.31494868 -0.85002244\n",
      "  0.3104003   0.12717055  0.35790483 -0.06325981 -0.02379183 -0.21037593]\n",
      "Epoch is: 32 and Cost is: 783.7114406095623 \n",
      " [ 5.06181933 -0.20332194  1.03435795  0.32948975  0.03546124 -0.48965913\n",
      " -0.55139659  0.24259263  0.40701073  0.07265742 -0.24766366 -1.00112174\n",
      "  0.60086187  0.24564561  0.30491321 -0.20694062  0.00651575 -0.16364835]\n",
      "Epoch is: 64 and Cost is: 723.3874014650798 \n",
      " [ 8.26520925e+00 -1.42825003e-01  1.16069598e+00  1.22274107e-01\n",
      " -6.30001609e-02 -6.49293786e-01 -5.90684058e-01  3.83775672e-01\n",
      "  2.70146297e-01  7.82482404e-02  1.94713378e-02 -1.20703317e+00\n",
      "  8.31315442e-01  2.21234438e-01  8.42485390e-02  2.17273074e-03\n",
      " -3.40558029e-02 -1.54484303e-01]\n"
     ]
    }
   ],
   "source": [
    "p_best = PerceptronClassifier2(**p_pipe.best_params_)\n",
    "p_best.fit(X_train, y_train)\n",
    "best_accuracy = accuracy_score(p_best.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My accuracy obtained by using best parameters is 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"My accuracy obtained by using best parameters is %.2f\" % best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
