{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyGaussianNB Class classifier\n",
    "A simple example of a classifier in the `sklearn` framework.   \n",
    "https://sklearn-template.readthedocs.io/en/latest/user_guide.html   \n",
    "This classifier simply identifies the most frequent class and always predicts that.  \n",
    "Implementing the classifier entails defining the `fit` and `predict` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Gaussian Naive Bayes  Classifier\n",
    "An implementation of a Gaussian Naive Class Classifier that fits into the scikit-learn framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.data_by_class = dict()\n",
    "        self.class_prior = dict()\n",
    "        self.feature_lkh = dict()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # Separate dataset by class\n",
    "        for i in range(len(X)):\n",
    "            vec = X[i]\n",
    "            class_label = y[i]\n",
    "            if class_label not in self.data_by_class:\n",
    "                self.data_by_class[class_label] = list()\n",
    "            self.data_by_class[class_label].append(vec)\n",
    "        \n",
    "        # Calculate class prior\n",
    "        self.class_prior = dict(Counter(y))\n",
    "        for cls in self.class_prior:\n",
    "            self.class_prior[cls] = 1.0 * self.class_prior[cls] / len(y)            \n",
    "        #print(self.class_prior)\n",
    "        \n",
    "        # summary stats on features X (mean and standard deviation)\n",
    "        for cls, data in self.data_by_class.items():\n",
    "            self.feature_lkh[cls] = {'mu':np.mean(self.data_by_class[cls], axis=0), 'sigma':np.std(self.data_by_class[cls], axis=0), 'cls_length':len(self.data_by_class[cls])}\n",
    "            \n",
    "        #print(self.feature_lkh)\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "    \n",
    "      \n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        def naive_bayes_pdf(mu, sigma, x_OneFeature):\n",
    "            return 1.0 / np.sqrt(2 * np.pi * (sigma**2) ) * np.exp(-1 * ((x_OneFeature - mu)**2) / (2 * (sigma**2)))   \n",
    "            \n",
    "            \n",
    "        def predict_X_OneRow(feature_lkh_stats, X_OneRow):\n",
    "            class_proba = dict()\n",
    "            \n",
    "            for cls in feature_lkh_stats:\n",
    "                params_list = list(zip(feature_lkh_stats[cls]['mu'], feature_lkh_stats[cls]['sigma'], X_OneRow))\n",
    "                lkh = list(map(lambda params: naive_bayes_pdf(params[0],params[1],params[2]), params_list))\n",
    "                class_proba[cls] = np.prod(lkh) * self.class_prior[cls]\n",
    "                \n",
    "            class_proba_normalized = dict()\n",
    "            for cls in class_proba:\n",
    "                class_proba_normalized[cls] = class_proba[cls] / sum(class_proba.values())    \n",
    "                \n",
    "            #print(class_proba_normalized)\n",
    "            \n",
    "            class_selected_index = np.argmax(list(class_proba_normalized.values()))        \n",
    "            class_selected = list(class_proba_normalized.keys())[class_selected_index]        \n",
    "            return class_selected\n",
    "    \n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        \n",
    "        predicted_class_labels = None\n",
    "        \n",
    "        if X.ndim == 2 and X.shape[0]>1:\n",
    "            predicted_class_labels = list(map(lambda X_OneRow : predict_X_OneRow(self.feature_lkh, X_OneRow), X))\n",
    "            #predicted_class_labels = [predict_X_OneRow(self.feature_lkh, X_OneRow) for X_OneRow in X]\n",
    "            predicted_class_labels = np.array(predicted_class_labels)\n",
    "        elif X.ndim ==1:\n",
    "            predicted_class_labels = predict_X_OneRow(self.feature_lkh, X)\n",
    "        else:\n",
    "            predicted_class_labels = None\n",
    "            \n",
    "        return predicted_class_labels\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MyGaussianNB Classifier with 4 Different Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load the penguines dataset\n",
    "penguins_af = pd.read_csv('penguines.csv')\n",
    "print(penguins_af.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "print(diabetes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the glassV2 dataset\n",
    "glassV2 = pd.read_csv('glassV2.csv')\n",
    "glassV2 = glassV2.replace({0.0:np.nan})\n",
    "print(glassV2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load the wine dataset\n",
    "wine = pd.read_csv('wine.csv')\n",
    "print(wine.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g species\n",
      "0            39.1           18.7              181.0       3750.0  Adelie\n",
      "1            39.5           17.4              186.0       3800.0  Adelie\n",
      "2            40.3           18.0              195.0       3250.0  Adelie\n",
      "4            36.7           19.3              193.0       3450.0  Adelie\n",
      "5            39.3           20.6              190.0       3650.0  Adelie\n",
      "Adelie       146\n",
      "Gentoo       119\n",
      "Chinstrap     68\n",
      "Name: species, dtype: int64\n",
      "   preg  plas  pres  skin  insu  mass   pedi  age          neg_pos\n",
      "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
      "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
      "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
      "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
      "4     0   137    40    35   168  43.1  2.288   33  tested_positive\n",
      "tested_negative    500\n",
      "tested_positive    268\n",
      "Name: neg_pos, dtype: int64\n",
      "        RI     Na    Mg    Al     Si     K    Ca     Ba     Fe    Type\n",
      "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.400  0.235  type_1\n",
      "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.075  0.120  type_1\n",
      "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.075  0.120  type_1\n",
      "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.075  0.105  type_1\n",
      "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.075  0.100  type_1\n",
      "type_2    76\n",
      "type_1    70\n",
      "type_7    29\n",
      "type_3    17\n",
      "type_5    13\n",
      "Name: Type, dtype: int64\n",
      "   Alcohol  Malic_acid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6        127           2.80   \n",
      "1    13.20        1.78  2.14               11.2        100           2.65   \n",
      "2    13.16        2.36  2.67               18.6        101           2.80   \n",
      "3    14.37        1.95  2.50               16.8        113           3.85   \n",
      "4    13.24        2.59  2.87               21.0        118           2.80   \n",
      "\n",
      "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   OD280/OD315_of_diluted_wines  Proline  class  \n",
      "0                          3.92     1065  Type1  \n",
      "1                          3.40     1050  Type1  \n",
      "2                          3.17     1185  Type1  \n",
      "3                          3.45     1480  Type1  \n",
      "4                          2.93      735  Type1  \n",
      "Type2    71\n",
      "Type1    59\n",
      "Type3    48\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean the data, and addressing the missing values \n",
    "\n",
    "# penguins dataset\n",
    "f_names = ['bill_length_mm', 'bill_depth_mm','flipper_length_mm', 'body_mass_g']\n",
    "penguins = penguins_af[f_names + ['species']]\n",
    "print(penguins.head())\n",
    "print(penguins[penguins.columns[-1]].value_counts())\n",
    "\n",
    "# diabetes dataset\n",
    "# Looks good, no need for cleaning\n",
    "print(diabetes.head())\n",
    "print(diabetes[diabetes.columns[-1]].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# glassv2 dataset\n",
    "# There is quite a few missing values appearing as 0, in the dataset, so some preprosessing need to be done by \n",
    "# replacing these 0s with null valunes in Python(np.nan) and then impute the meaning values in those locations.\n",
    "glassV2['Type'] = [ 'type_' + str(T) for T in glassV2['Type']  ]\n",
    "glassV2.replace({0.0:np.nan})\n",
    "glassV2[glassV2.columns[0: len(glassV2.columns)-1]] = KNNImputer(n_neighbors=2).fit_transform(glassV2[glassV2.columns[0: len(glassV2.columns)-1]])\n",
    "glassV2[glassV2.columns[0: len(glassV2.columns)-1]] = SimpleImputer(strategy='mean').fit_transform(glassV2[glassV2.columns[0: len(glassV2.columns)-1]])\n",
    "\n",
    "\n",
    "print(glassV2.head())\n",
    "print(glassV2[glassV2.columns[-1]].value_counts())\n",
    "\n",
    "\n",
    "# wine dataset\n",
    "# Looks good, no need for cleaning\n",
    "print(wine.head())\n",
    "print(wine[wine.columns[-1]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"penguins\" dataset with the \"My_GNB\" model ---------------\n",
      "\n",
      "Dataset: | penguins |, Model: | My_GNB |, \n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.97\n",
      "f1: 0.98\n",
      "\n",
      "nConfusion matrix:\n",
      "[[39  0  0]\n",
      " [ 1  9  0]\n",
      " [ 0  0 18]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.97\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"penguins\" dataset with the \"SKL_GNB\" model ---------------\n",
      "\n",
      "Dataset: | penguins |, Model: | SKL_GNB |, \n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.97\n",
      "f1: 0.98\n",
      "\n",
      "nConfusion matrix:\n",
      "[[39  0  0]\n",
      " [ 1  9  0]\n",
      " [ 0  0 18]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.97\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"penguins\" dataset with the \"KNN\" model ---------------\n",
      "\n",
      "Dataset: | penguins |, Model: | KNN |, \n",
      "\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "f1: 1.00\n",
      "\n",
      "nConfusion matrix:\n",
      "[[39  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 18]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.99\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"penguins\" dataset with the \"SVM\" model ---------------\n",
      "\n",
      "Dataset: | penguins |, Model: | SVM |, \n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.97\n",
      "f1: 0.98\n",
      "\n",
      "nConfusion matrix:\n",
      "[[39  0  0]\n",
      " [ 1  9  0]\n",
      " [ 0  0 18]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.98\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"penguins\" dataset with the \"DecisionTree\" model ---------------\n",
      "\n",
      "Dataset: | penguins |, Model: | DecisionTree |, \n",
      "\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "f1: 1.00\n",
      "\n",
      "nConfusion matrix:\n",
      "[[39  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 18]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.97\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"diabetes\" dataset with the \"My_GNB\" model ---------------\n",
      "\n",
      "Dataset: | diabetes |, Model: | My_GNB |, \n",
      "\n",
      "Accuracy: 0.79\n",
      "Precision: 0.76\n",
      "Recall: 0.74\n",
      "f1: 0.75\n",
      "\n",
      "nConfusion matrix:\n",
      "[[93 14]\n",
      " [18 29]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.76\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"diabetes\" dataset with the \"SKL_GNB\" model ---------------\n",
      "\n",
      "Dataset: | diabetes |, Model: | SKL_GNB |, \n",
      "\n",
      "Accuracy: 0.79\n",
      "Precision: 0.76\n",
      "Recall: 0.74\n",
      "f1: 0.75\n",
      "\n",
      "nConfusion matrix:\n",
      "[[93 14]\n",
      " [18 29]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.76\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"diabetes\" dataset with the \"KNN\" model ---------------\n",
      "\n",
      "Dataset: | diabetes |, Model: | KNN |, \n",
      "\n",
      "Accuracy: 0.77\n",
      "Precision: 0.73\n",
      "Recall: 0.72\n",
      "f1: 0.72\n",
      "\n",
      "nConfusion matrix:\n",
      "[[92 15]\n",
      " [20 27]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.74\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"diabetes\" dataset with the \"SVM\" model ---------------\n",
      "\n",
      "Dataset: | diabetes |, Model: | SVM |, \n",
      "\n",
      "Accuracy: 0.82\n",
      "Precision: 0.80\n",
      "Recall: 0.76\n",
      "f1: 0.77\n",
      "\n",
      "nConfusion matrix:\n",
      "[[98  9]\n",
      " [19 28]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.77\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"diabetes\" dataset with the \"DecisionTree\" model ---------------\n",
      "\n",
      "Dataset: | diabetes |, Model: | DecisionTree |, \n",
      "\n",
      "Accuracy: 0.73\n",
      "Precision: 0.70\n",
      "Recall: 0.71\n",
      "f1: 0.70\n",
      "\n",
      "nConfusion matrix:\n",
      "[[82 25]\n",
      " [16 31]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.70\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"wine\" dataset with the \"My_GNB\" model ---------------\n",
      "\n",
      "Dataset: | wine |, Model: | My_GNB |, \n",
      "\n",
      "Accuracy: 0.92\n",
      "Precision: 0.91\n",
      "Recall: 0.94\n",
      "f1: 0.92\n",
      "\n",
      "nConfusion matrix:\n",
      "[[14  0  0]\n",
      " [ 2 13  1]\n",
      " [ 0  0  6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.98\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"wine\" dataset with the \"SKL_GNB\" model ---------------\n",
      "\n",
      "Dataset: | wine |, Model: | SKL_GNB |, \n",
      "\n",
      "Accuracy: 0.92\n",
      "Precision: 0.91\n",
      "Recall: 0.94\n",
      "f1: 0.92\n",
      "\n",
      "nConfusion matrix:\n",
      "[[14  0  0]\n",
      " [ 2 13  1]\n",
      " [ 0  0  6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.98\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"wine\" dataset with the \"KNN\" model ---------------\n",
      "\n",
      "Dataset: | wine |, Model: | KNN |, \n",
      "\n",
      "Accuracy: 0.97\n",
      "Precision: 0.95\n",
      "Recall: 0.98\n",
      "f1: 0.96\n",
      "\n",
      "nConfusion matrix:\n",
      "[[14  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.95\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"wine\" dataset with the \"SVM\" model ---------------\n",
      "\n",
      "Dataset: | wine |, Model: | SVM |, \n",
      "\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "f1: 1.00\n",
      "\n",
      "nConfusion matrix:\n",
      "[[14  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0  6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.98\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"wine\" dataset with the \"DecisionTree\" model ---------------\n",
      "\n",
      "Dataset: | wine |, Model: | DecisionTree |, \n",
      "\n",
      "Accuracy: 0.94\n",
      "Precision: 0.93\n",
      "Recall: 0.96\n",
      "f1: 0.94\n",
      "\n",
      "nConfusion matrix:\n",
      "[[13  1  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.90\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"glassV2\" dataset with the \"My_GNB\" model ---------------\n",
      "\n",
      "Dataset: | glassV2 |, Model: | My_GNB |, \n",
      "\n",
      "Accuracy: 0.56\n",
      "Precision: 0.58\n",
      "Recall: 0.59\n",
      "f1: 0.57\n",
      "\n",
      "nConfusion matrix:\n",
      "[[8 2 3 0 0]\n",
      " [8 5 0 1 0]\n",
      " [4 0 0 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.47\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"glassV2\" dataset with the \"SKL_GNB\" model ---------------\n",
      "\n",
      "Dataset: | glassV2 |, Model: | SKL_GNB |, \n",
      "\n",
      "Accuracy: 0.56\n",
      "Precision: 0.58\n",
      "Recall: 0.59\n",
      "f1: 0.57\n",
      "\n",
      "nConfusion matrix:\n",
      "[[8 2 3 0 0]\n",
      " [8 5 0 1 0]\n",
      " [4 0 0 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.47\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"glassV2\" dataset with the \"KNN\" model ---------------\n",
      "\n",
      "Dataset: | glassV2 |, Model: | KNN |, \n",
      "\n",
      "Accuracy: 0.61\n",
      "Precision: 0.62\n",
      "Recall: 0.53\n",
      "f1: 0.55\n",
      "\n",
      "nConfusion matrix:\n",
      "[[ 8  4  1  0  0]\n",
      " [ 4 10  0  0  0]\n",
      " [ 3  1  0  0  0]\n",
      " [ 0  2  0  2  0]\n",
      " [ 0  1  0  0  5]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.71\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"glassV2\" dataset with the \"SVM\" model ---------------\n",
      "\n",
      "Dataset: | glassV2 |, Model: | SVM |, \n",
      "\n",
      "Accuracy: 0.46\n",
      "Precision: 0.51\n",
      "Recall: 0.42\n",
      "f1: 0.41\n",
      "\n",
      "nConfusion matrix:\n",
      "[[ 1 12  0  0  0]\n",
      " [ 3 11  0  0  0]\n",
      " [ 2  2  0  0  0]\n",
      " [ 0  3  0  1  0]\n",
      " [ 0  0  0  0  6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.55\n",
      "\n",
      "\n",
      "\n",
      "------------- Training the classifier on the \"glassV2\" dataset with the \"DecisionTree\" model ---------------\n",
      "\n",
      "Dataset: | glassV2 |, Model: | DecisionTree |, \n",
      "\n",
      "Accuracy: 0.76\n",
      "Precision: 0.84\n",
      "Recall: 0.75\n",
      "f1: 0.77\n",
      "\n",
      "nConfusion matrix:\n",
      "[[ 9  3  0  0  1]\n",
      " [ 2 11  0  0  1]\n",
      " [ 2  0  2  0  0]\n",
      " [ 0  1  0  3  0]\n",
      " [ 0  0  0  0  6]]\n",
      "\n",
      "10-fold cross validation score (\"Accuracy\") : 0.61\n"
     ]
    }
   ],
   "source": [
    "# Compare the MyGaussianNB implementation with the scikit-learn GaussianNB classifier to see if the MyGaussianNB generate\n",
    "# the same results as its scikit-learn version. Also, other classifier models such as Suport Vector Machine, KNN, and Decision\n",
    "# Tree are also being used as a comparion across the 4 different datasets.\n",
    "\n",
    "datasets = {'penguins': penguins, 'diabetes':diabetes,'wine':wine,'glassV2':glassV2 }\n",
    "\n",
    "dataset_names = list(datasets.keys())\n",
    "\n",
    "classifier_comparison_table = dict() \n",
    "\n",
    "cross_validation_folds = 10  # e#\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    \n",
    "    dataset = datasets[dataset_name].copy()\n",
    "    feature_names = dataset.columns\n",
    "    y = dataset.pop(dataset.columns[-1]).values\n",
    "    X_raw = dataset.values\n",
    "    \n",
    "    my_gnb = MyGaussianNB()\n",
    "    sk_gnb = GaussianNB()\n",
    "    \n",
    "    svm = SVC(kernel = 'linear',C=1)\n",
    "    kNN = KNeighborsClassifier(n_neighbors=3)  \n",
    "    dtree = DecisionTreeClassifier(criterion='entropy')\n",
    "    \n",
    "    models = {'My_GNB':my_gnb, 'SKL_GNB':sk_gnb, 'KNN':kNN, 'SVM':svm, 'DecisionTree':dtree}\n",
    "    classifier_names = list(models.keys())\n",
    "    \n",
    "    scalers = {'MinMax_Scaler':MinMaxScaler(), 'Standard_Scaler': StandardScaler()}    \n",
    "    \n",
    "    for classifier_name in classifier_names:\n",
    "        \n",
    "        print('\\n\\n\\n------------- Training the classifier on the \"{0}\" dataset with the \"{1}\" model ---------------'.format(dataset_name,classifier_name))\n",
    "        \n",
    "        steps = [('scaler', scalers['MinMax_Scaler']), ('gaussian_naive_classifier', models[classifier_name])]\n",
    "        pipeline = Pipeline(steps)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=0)\n",
    "        # training the model from the training set and predict class in the test set \n",
    "        fitted_model = pipeline.fit(X_train, y_train)\n",
    "        y_pred = fitted_model.predict(X_test)\n",
    "        \n",
    "        # accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('\\nDataset: | {0} |, Model: | {1} |, \\n\\nAccuracy: {2:.2f}'.format(dataset_name, classifier_name, accuracy))\n",
    "        \n",
    "        # precision score\n",
    "        precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        print('Precision: {0:.2f}'.format(precision))\n",
    "\n",
    "        # recall score\n",
    "        recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        print('Recall: {0:.2f}'.format( recall))\n",
    "\n",
    "        # f1 score\n",
    "        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        print('f1: {0:.2f}'.format(f1))    \n",
    "        \n",
    "        # confusion matrix\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print('\\nnConfusion matrix:\\n{0}'.format(confusion))\n",
    "\n",
    "        # cross validation\n",
    "        cv_scores = cross_val_score(pipeline, X_raw, y, scoring = 'accuracy', cv=cross_validation_folds, n_jobs=-1)\n",
    "        print('\\n{0}-fold cross validation score (\"Accuracy\") : {1:.2f}'.format(cross_validation_folds, np.mean(cv_scores)) )\n",
    "        \n",
    "        col_label = dataset_name + '_' + classifier_name\n",
    "        \n",
    "        if col_label not in classifier_comparison_table:\n",
    "            classifier_comparison_table[col_label] = list()\n",
    "        \n",
    "        classifier_comparison_table[col_label].extend([accuracy, precision, recall, f1, np.mean(cv_scores)])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penguins_My_GNB</th>\n",
       "      <th>penguins_SKL_GNB</th>\n",
       "      <th>penguins_KNN</th>\n",
       "      <th>penguins_SVM</th>\n",
       "      <th>penguins_DecisionTree</th>\n",
       "      <th>diabetes_My_GNB</th>\n",
       "      <th>diabetes_SKL_GNB</th>\n",
       "      <th>diabetes_KNN</th>\n",
       "      <th>diabetes_SVM</th>\n",
       "      <th>diabetes_DecisionTree</th>\n",
       "      <th>wine_My_GNB</th>\n",
       "      <th>wine_SKL_GNB</th>\n",
       "      <th>wine_KNN</th>\n",
       "      <th>wine_SVM</th>\n",
       "      <th>wine_DecisionTree</th>\n",
       "      <th>glassV2_My_GNB</th>\n",
       "      <th>glassV2_SKL_GNB</th>\n",
       "      <th>glassV2_KNN</th>\n",
       "      <th>glassV2_SVM</th>\n",
       "      <th>glassV2_DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.756098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.756128</td>\n",
       "      <td>0.756128</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.797182</td>\n",
       "      <td>0.695153</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931548</td>\n",
       "      <td>0.582857</td>\n",
       "      <td>0.582857</td>\n",
       "      <td>0.617778</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.835128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.743090</td>\n",
       "      <td>0.743090</td>\n",
       "      <td>0.717141</td>\n",
       "      <td>0.755816</td>\n",
       "      <td>0.712965</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.594505</td>\n",
       "      <td>0.594505</td>\n",
       "      <td>0.532601</td>\n",
       "      <td>0.422527</td>\n",
       "      <td>0.745604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.978237</td>\n",
       "      <td>0.978237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748828</td>\n",
       "      <td>0.748828</td>\n",
       "      <td>0.723462</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.700971</td>\n",
       "      <td>0.917654</td>\n",
       "      <td>0.917654</td>\n",
       "      <td>0.963606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941180</td>\n",
       "      <td>0.569986</td>\n",
       "      <td>0.569986</td>\n",
       "      <td>0.554437</td>\n",
       "      <td>0.405815</td>\n",
       "      <td>0.766376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_accuracy</th>\n",
       "      <td>0.969964</td>\n",
       "      <td>0.969964</td>\n",
       "      <td>0.988057</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.973084</td>\n",
       "      <td>0.756494</td>\n",
       "      <td>0.756494</td>\n",
       "      <td>0.739542</td>\n",
       "      <td>0.768216</td>\n",
       "      <td>0.696565</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.983007</td>\n",
       "      <td>0.898366</td>\n",
       "      <td>0.473810</td>\n",
       "      <td>0.473810</td>\n",
       "      <td>0.713095</td>\n",
       "      <td>0.551667</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             penguins_My_GNB  penguins_SKL_GNB  penguins_KNN  penguins_SVM  \\\n",
       "accuracy            0.985075          0.985075      1.000000      0.985075   \n",
       "precision           0.991667          0.991667      1.000000      0.991667   \n",
       "recall              0.966667          0.966667      1.000000      0.966667   \n",
       "f1_score            0.978237          0.978237      1.000000      0.978237   \n",
       "cv_accuracy         0.969964          0.969964      0.988057      0.981996   \n",
       "\n",
       "             penguins_DecisionTree  diabetes_My_GNB  diabetes_SKL_GNB  \\\n",
       "accuracy                  1.000000         0.792208          0.792208   \n",
       "precision                 1.000000         0.756128          0.756128   \n",
       "recall                    1.000000         0.743090          0.743090   \n",
       "f1_score                  1.000000         0.748828          0.748828   \n",
       "cv_accuracy               0.973084         0.756494          0.756494   \n",
       "\n",
       "             diabetes_KNN  diabetes_SVM  diabetes_DecisionTree  wine_My_GNB  \\\n",
       "accuracy         0.772727      0.818182               0.733766     0.916667   \n",
       "precision        0.732143      0.797182               0.695153     0.910714   \n",
       "recall           0.717141      0.755816               0.712965     0.937500   \n",
       "f1_score         0.723462      0.770833               0.700971     0.917654   \n",
       "cv_accuracy      0.739542      0.768216               0.696565     0.977778   \n",
       "\n",
       "             wine_SKL_GNB  wine_KNN  wine_SVM  wine_DecisionTree  \\\n",
       "accuracy         0.916667  0.972222  1.000000           0.944444   \n",
       "precision        0.910714  0.952381  1.000000           0.931548   \n",
       "recall           0.937500  0.979167  1.000000           0.955357   \n",
       "f1_score         0.917654  0.963606  1.000000           0.941180   \n",
       "cv_accuracy      0.977778  0.949020  0.983007           0.898366   \n",
       "\n",
       "             glassV2_My_GNB  glassV2_SKL_GNB  glassV2_KNN  glassV2_SVM  \\\n",
       "accuracy           0.560976         0.560976     0.609756     0.463415   \n",
       "precision          0.582857         0.582857     0.617778     0.511905   \n",
       "recall             0.594505         0.594505     0.532601     0.422527   \n",
       "f1_score           0.569986         0.569986     0.554437     0.405815   \n",
       "cv_accuracy        0.473810         0.473810     0.713095     0.551667   \n",
       "\n",
       "             glassV2_DecisionTree  \n",
       "accuracy                 0.756098  \n",
       "precision                0.835128  \n",
       "recall                   0.745604  \n",
       "f1_score                 0.766376  \n",
       "cv_accuracy              0.614286  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_comparison_table = pd.DataFrame(classifier_comparison_table, index=['accuracy', 'precision', 'recall', 'f1_score', 'cv_accuracy'])\n",
    "classifier_comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The performance metrics being used are: 1) Accuracy; 2) Precision; 3) Recall; 4) f1 score; 5) confusion matrix; 6) 10-fold cross-validation for average accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The MyGaussian implementation generates exactly the same confusion matrix and various performance scores ( accuracy, precision, recall, f1 score, and 10-fold cross-validation for average accuracy) mentioned above as the scikit-learn GaussianNB implementation, which means this MyGaussian implementation has identifical performance as the scikit-learn GaussianNB version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In terms of different models, the 10-fold cross-validation for average accuracy score indicates that: 1) the KNN method and the SVM method have the best performance for the penguines dataset, which is slightly better than the Gaussian Naive Bayes method; 2) the Gaissian Naive Bayes model has the best performance for the diabetes dataset; 3) the SVM has the best performance for the wine dataset, but it is just marginally better than the aissian Naive Bayes method; 4) The Decision Tree model outperforms other model for the glassV2 dataset, and the Gaissian Naive Bayes model is quite disadvantagous for this dataset among all of the classifier methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
